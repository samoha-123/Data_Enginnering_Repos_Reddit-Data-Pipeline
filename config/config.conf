[database]
database_host = localhost
database_name = airflow_reddit
database_port = 5432
database_username = postgres
database_password = postgres

[file_paths]
input_path = /opt/airflow/data/input
output_path = /opt/airflow/data/output
reddit_output_file_name = your_reddit_output_file_name

[api_keys]
reddit_secret_key = your_reddit_secret_key
reddit_client_id = your_reddit_client_id

[aws]
aws_access_key_id = your_access_key
aws_secret_access_key= your_secret_key
aws_region = your-region
aws_bucket_name = your_bucket_name
aws_glue_job_name = your_glue_job_name
aws_glue_crawler_name = your_glue_crawler_name
aws_s3_raw_file_name = your_s3_raw_file_name
aws_s3_transformed_file_name = your_s3_transformed_file_name
aws_s3_airflow_log_bucket = your_s3_airflow_log_bucket
aws_s3_airflow_log_key = your_s3_airflow_log_key (llocation of the log folder inside the airflow log bucket)
use_local_glue_transform_script = True (whether to use local glue script or not)

[etl_settings]
batch_size = 100
error_handling = abort
log_level = info